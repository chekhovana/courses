{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"movie_reviews.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Q-5UeF4Tus2AygCtDVMC51OHW8LS41Wn","authorship_tag":"ABX9TyNhzRHfJe31/gedgK3EerUN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)"],"metadata":{"id":"_psoWSCPq3Dq"}},{"cell_type":"markdown","metadata":{"id":"-tLVbDiD4BuP"},"source":["<h1>Анализ тональности отзывов на фильмы:\n","строим простые модели</h1>\n"," \n","\n","В этом задании вам предлагается начать разбираться с задачей анализа тональности отзывов на примере сентимент-анализа отзывов на фильмы.\n","\n","Мы будем использовать стандартный датасет из nltk, уже возникавший в одном из примеров в предыдущих курсах. Для того, чтобы импортировать необходимый модуль, напишите:\n","\n"," \n","<code>from nltk.corpus import movie_reviews</code>\n"," \n","\n","Чтобы получить id-шники негативных и позитивных отзывов:\n","\n","<code> \n","negids = movie_reviews.fileids('neg')<br>\n","posids = movie_reviews.fileids('pos')\n","</code> \n","\n","Чтобы получить список негативных отзывов:\n","\n","<code> \n","negfeats = [movie_reviews.words(fileids=[f]) for f in negids]\n","</code> \n","\n","<h2>Инструкция по выполнению</h2>\n","\n","В некоторых пунктах нужно получить ответ - число или строку, которые будет нужно набирать в текстовых файлах и прикреплять в ответах на вопросы. Десятичные дроби записывайте через точку.\n","\n","<ol><li>Создайте список из текстов всех имеющихся отзывов, а также список с классами, которые будет использовать ваш классификатор - 0 для негативных отзывов и 1 для позитивных.</li>\n","<li>Подсчитайте количество отзывов в выборке.</li>\n","<li>Подсчитайте долю класса 1 в выборке.</li>\n","<li>Импортируйте CountVectorizer из sklearn.feature_extraction.text. Попробуйте использовать его с настройками по умолчанию для того, чтобы получить признаковое представление каждого текста. Скорее всего, попытка не увенчается успехом. Разберитесь, в чем причина, и добейтесь того, чтобы метод fit_transform у CountVectorizer успешно отрабатывал. Подсчитайте количество признаков в CountVectorizer. Никакой предварительной обработки текста (удаление стоп-слов, нормализация слов) на этом шаге делать не надо, в качестве признаков должны использоваться частоты слов.</li>\n","<li>Соберите pipeline из CountVectorizer и LogisticRegression c настройками по-умолчанию и с помощью cross_val_score (также со стандартными настройками) оцените получаемое \"из коробки\" качество по accuracy.</li>\n","<li>Аналогично accuracy, оцените качество по ROC AUC.\n","Обучите логистическую регрессию на всей доступной вам выборке и выведите 5 наиболее важных для модели признаков (подумайте, какие именно признаки стоит считать такими). Вам могут пригодиться метод get_feature_names() или поле vocabulary_ у класса CountVectorizer.</li>\n","</ol>"]},{"cell_type":"code","metadata":{"id":"SshozRvtA6I_"},"source":["import numpy as np\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import cross_val_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K8bATwTI6JIJ"},"source":["Загружаем датасет"]},{"cell_type":"code","metadata":{"id":"HZlsujh4a9VL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641121708739,"user_tz":-180,"elapsed":1167,"user":{"displayName":"Надежда Чехова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSJHZgegxNfZHz-DHNitm4K7fL7sLHVtvAWS50Ceg=s64","userId":"05232737027527319731"}},"outputId":"a59d2f24-da29-4d7b-c04d-65fa65af6a26"},"source":["import nltk\n","from nltk.corpus import movie_reviews\n","nltk.download('movie_reviews')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"vHFoa7tY6Mst"},"source":["Формируем массив отзывов и их меток (0 - отрицательный отзыв, 1 - положительный)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5AZGbFb7I9-A","executionInfo":{"status":"ok","timestamp":1641121710311,"user_tz":-180,"elapsed":1579,"user":{"displayName":"Надежда Чехова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSJHZgegxNfZHz-DHNitm4K7fL7sLHVtvAWS50Ceg=s64","userId":"05232737027527319731"}},"outputId":"e04b142d-2df4-40e9-ed1d-e8e8674ce2a5"},"source":["negids = movie_reviews.fileids('neg') \n","posids = movie_reviews.fileids('pos')\n","print('Количество положительных отзывов', len(posids))\n","print('Количество отрицательных отзывов', len(negids))\n","\n","neg_reviews = [' '.join(movie_reviews.words(fileids=[f])) for f in negids]\n","pos_reviews = [' '.join(movie_reviews.words(fileids=[f])) for f in posids]\n","corpus = neg_reviews + pos_reviews\n","labels = [0] * len(neg_reviews) + [1] * len(pos_reviews)\n","print('Общее количество отзывов', len(corpus))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Количество положительных отзывов 1000\n","Количество отрицательных отзывов 1000\n","Общее количество отзывов 2000\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PHSgjPiLAvE_","executionInfo":{"status":"ok","timestamp":1641121710674,"user_tz":-180,"elapsed":370,"user":{"displayName":"Надежда Чехова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSJHZgegxNfZHz-DHNitm4K7fL7sLHVtvAWS50Ceg=s64","userId":"05232737027527319731"}},"outputId":"3bcc83c0-4987-401b-df98-eaea03cf5bb2"},"source":["vectorizer = CountVectorizer()\n","x = vectorizer.fit_transform(corpus)\n","print('Количество признаков', x.shape[1])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Количество признаков 39659\n"]}]},{"cell_type":"markdown","metadata":{"id":"Gnex0c45JqtN"},"source":["Оценим качество классификации, рассчитав accuracy и roc-auc"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JJ0uf2KD_7sj","executionInfo":{"status":"ok","timestamp":1641121737232,"user_tz":-180,"elapsed":26562,"user":{"displayName":"Надежда Чехова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSJHZgegxNfZHz-DHNitm4K7fL7sLHVtvAWS50Ceg=s64","userId":"05232737027527319731"}},"outputId":"34567f13-b666-4712-a9c0-7dd31aae42d6"},"source":["%%time\n","clf = LogisticRegression(max_iter=1000)\n","pline = Pipeline([(\"vectorizer\", vectorizer), (\"classifier\", clf)])\n","print('Точность классификации', cross_val_score(pline, corpus, labels).mean())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Точность классификации 0.8445\n","CPU times: user 20 s, sys: 16.5 s, total: 36.6 s\n","Wall time: 26.3 s\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ex8rxNOXGwfy","executionInfo":{"status":"ok","timestamp":1641121756273,"user_tz":-180,"elapsed":19055,"user":{"displayName":"Надежда Чехова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSJHZgegxNfZHz-DHNitm4K7fL7sLHVtvAWS50Ceg=s64","userId":"05232737027527319731"}},"outputId":"c72d95d7-055d-452f-e2a7-4898f2c904ef"},"source":["print('roc auc', cross_val_score(pline, corpus, labels, scoring='roc_auc').mean())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["roc auc 0.9162949999999999\n"]}]},{"cell_type":"markdown","metadata":{"id":"5-oTXxyetcLJ"},"source":["Обучаем модель на всей выборке"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CkQ9xAYLHus1","executionInfo":{"status":"ok","timestamp":1641121761046,"user_tz":-180,"elapsed":4791,"user":{"displayName":"Надежда Чехова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSJHZgegxNfZHz-DHNitm4K7fL7sLHVtvAWS50Ceg=s64","userId":"05232737027527319731"}},"outputId":"1ea10840-ed3b-4264-f091-e499a8a26925"},"source":["pline.fit(corpus, labels)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('vectorizer', CountVectorizer()),\n","                ('classifier', LogisticRegression(max_iter=1000))])"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"WZgJ_lGftu4p"},"source":["Выводим 5 наиболее значимых слов, им соответствуют максимальные по модулю веса модели"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"6zavL8WFIxt0","executionInfo":{"status":"ok","timestamp":1641121761048,"user_tz":-180,"elapsed":31,"user":{"displayName":"Надежда Чехова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSJHZgegxNfZHz-DHNitm4K7fL7sLHVtvAWS50Ceg=s64","userId":"05232737027527319731"}},"outputId":"bb52e717-15ef-49e4-9c82-dbf107a5f97e"},"source":["imp_indexes = np.argsort(np.abs(clf.coef_[0]))[-5:][::-1]\n","res = [vectorizer.get_feature_names()[i] for i in imp_indexes]\n","''.join(res)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'badunfortunatelyworstfunnothing'"]},"metadata":{},"execution_count":8}]}]}