{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4.3_online_goods_recommender.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1MaLseLjvVhILFKv2Q5yxJve4TBndxVwY","authorship_tag":"ABX9TyOP6m978eztYHp2mhjk8xaq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Описание задачи\n","Небольшой интернет-магазин попросил вас добавить ранжирование товаров в блок \"Смотрели ранее\" - в нем теперь надо показывать не последние просмотренные пользователем товары, а те товары из просмотренных, которые он наиболее вероятно купит. Качество вашего решения будет оцениваться по количеству покупок в сравнении с прошлым решением в ходе А/В теста, т.к. по доходу от продаж статзначимость будет достигаться дольше из-за разброса цен. Таким образом, ничего заранее не зная про корреляцию оффлайновых и онлайновых метрик качества, в начале проекта вы можете лишь постараться оптимизировать recall@k и precision@k.\n","\n","### Задание\n","Задание посвящено построению простых бейзлайнов для этой задачи: ранжирование просмотренных товаров по частоте просмотров и по частоте покупок. Эти бейзлайны, с одной стороны, могут помочь вам грубо оценить возможный эффект от ранжирования товаров в блоке - например, чтобы вписать какие-то числа в коммерческое предложение заказчику, а с другой стороны, могут оказаться самым хорошим вариантом, если данных очень мало (недостаточно для обучения даже простых моделей).\n","\n","### Входные данные\n","\n","Вам дается две выборки с пользовательскими сессиями - id-шниками просмотренных и id-шниками купленных товаров. Одна выборка будет использоваться для обучения (оценки популярностей товаров), а другая - для теста.\n","\n","В файлах записаны сессии по одной в каждой строке. Формат сессии: id просмотренных товаров через , затем идёт ; после чего следуют id купленных товаров (если такие имеются), разделённые запятой. Например, 1,2,3,4; или 1,2,3,4;5,6.\n","\n","Гарантируется, что среди id купленных товаров все различные.\n","\n","### Важно:\n","\n","Сессии, в которых пользователь ничего не купил, исключаем из оценки качества.\n","Если товар не встречался в обучающей выборке, его популярность равна 0.\n","Рекомендуем разные товары. И их число должно быть не больше, чем количество различных просмотренных пользователем товаров.\n","Рекомендаций всегда не больше, чем минимум из двух чисел: количество просмотренных пользователем товаров и k в recall@k / precision@k.\n","\n","### Задание\n","\n","1. На обучении постройте частоты появления id в просмотренных и в купленных (id может несколько раз появляться в просмотренных, все появления надо учитывать)\n","2. Реализуйте два алгоритма рекомендаций:\n","    - сортировка просмотренных id по популярности (частота появления в просмотренных),\n","    - сортировка просмотренных id по покупаемости (частота появления в покупках).\n","3. Для данных алгоритмов выпишите через пробел AverageRecall@1, AveragePrecision@1, AverageRecall@5, AveragePrecision@5 на обучающей и тестовых выборках, округляя до 2 знака после запятой. Это будут ваши ответы в этом задании. Посмотрите, как они соотносятся друг с другом. Где качество получилось выше? Значимо ли это различие? Обратите внимание на различие качества на обучающей и тестовой выборке в случае рекомендаций по частотам покупки.\n","\n","Если частота одинаковая, то сортировать нужно по возрастанию момента просмотра (чем раньше появился в просмотренных, тем больше приоритет)\n","\n","\n"," "],"metadata":{"id":"EE1KI7UnaXT-"}},{"cell_type":"code","metadata":{"id":"t9w8Z8VCn0R-","executionInfo":{"status":"ok","timestamp":1641121039635,"user_tz":-180,"elapsed":378,"user":{"displayName":"Надежда Чехова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSJHZgegxNfZHz-DHNitm4K7fL7sLHVtvAWS50Ceg=s64","userId":"05232737027527319731"}}},"source":["import pandas as pd\n","from collections import defaultdict"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"pMyLkbpAn21I","executionInfo":{"status":"ok","timestamp":1641121041025,"user_tz":-180,"elapsed":1397,"user":{"displayName":"Надежда Чехова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSJHZgegxNfZHz-DHNitm4K7fL7sLHVtvAWS50Ceg=s64","userId":"05232737027527319731"}}},"source":["def read_dataset(fname):\n","    data = pd.read_csv(fname, sep=';', names=['views', 'purchases'])\n","    for c in data.columns:\n","        data[c] = data[c].apply(\n","            lambda x: [int(v) for v in x.split(',')] if pd.notna(x) else x)\n","    return data\n","\n","\n","folder = 'https://raw.githubusercontent.com/chekhovana/courses/main/machine_learning/5_tasks/4_recommender_systems/data/'\n","train = read_dataset(folder + '4.3_coursera_sessions_train.txt')\n","test = read_dataset(folder + '4.3_coursera_sessions_test.txt')\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ImOUtUlodHF","executionInfo":{"status":"ok","timestamp":1641121046405,"user_tz":-180,"elapsed":284,"user":{"displayName":"Надежда Чехова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSJHZgegxNfZHz-DHNitm4K7fL7sLHVtvAWS50Ceg=s64","userId":"05232737027527319731"}}},"source":["def get_counts(x):\n","    x = x.dropna()\n","    counter = defaultdict(int)\n","    for lst in x:\n","        for val in lst:\n","            counter[val] += 1\n","    return counter\n","\n","\n","def remove_dups(lst):\n","    seen = set()\n","    return [x for x in lst if not (x in seen or seen.add(x))]\n","\n","\n","def sort_by_counts(views, counts):\n","    return sorted(views, key=lambda x: counts[x], reverse=True)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6u2me_ri2GVs","executionInfo":{"status":"ok","timestamp":1641121222235,"user_tz":-180,"elapsed":1709,"user":{"displayName":"Надежда Чехова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSJHZgegxNfZHz-DHNitm4K7fL7sLHVtvAWS50Ceg=s64","userId":"05232737027527319731"}},"outputId":"951fbee0-53db-4d58-ba64-b0b537c8cd67"},"source":["def get_precision(row, k):\n","    recommended = row['views'][:k]\n","    purchased = row['purchases']\n","    precision = [item for item in purchased if item in recommended]\n","    return len(precision) / k\n","\n","\n","def get_recall(row, k):\n","    recommended = row['views'][:k]\n","    purchased = row['purchases']\n","    recall = [item for item in recommended if item in purchased]\n","    return len(recall) / len(purchased)\n","\n","\n","def get_metrics(df, counts):\n","    metrics = df[df['purchases'].notna()].copy()\n","    metrics['views'] = metrics['views'].apply(remove_dups)\n","    metrics['views'] = metrics['views'].apply(sort_by_counts, counts=counts)\n","    metrics = [[round(metrics.apply(f, k=k, axis=1).mean(), 4) \n","        for f in (get_recall, get_precision)] for k in [1, 5]]\n","    return sum(metrics, [])\n","\n","view_counts = get_counts(train['views'])\n","purchase_counts = get_counts(train['purchases'])\n","print('Рекомендации по частоте просмотров, качество на обучающей выборке')\n","print(get_metrics(train, view_counts))\n","print('Рекомендации по частоте просмотров, качество на тестовой выборке')\n","print(get_metrics(train, purchase_counts))\n","print('Рекомендации по частоте покупок, качество на обучающей выборке')\n","print(get_metrics(test, view_counts))\n","print('Рекомендации по частоте покупок, качество на тестовой выборке')\n","print(get_metrics(test, purchase_counts))"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Рекомендации по частоте просмотров, качество на обучающей выборке\n","[0.4426, 0.5122, 0.8247, 0.2125]\n","Рекомендации по частоте просмотров, качество на тестовой выборке\n","[0.6884, 0.8038, 0.9263, 0.2525]\n","Рекомендации по частоте покупок, качество на обучающей выборке\n","[0.4173, 0.4813, 0.8, 0.2038]\n","Рекомендации по частоте покупок, качество на тестовой выборке\n","[0.4606, 0.5277, 0.8202, 0.2101]\n"]}]}]}