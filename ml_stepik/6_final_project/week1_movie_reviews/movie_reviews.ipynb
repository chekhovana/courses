{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"movie_reviews.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Q-5UeF4Tus2AygCtDVMC51OHW8LS41Wn","authorship_tag":"ABX9TyP8BrObB6pvcKqbJaSZWrNR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-tLVbDiD4BuP"},"source":["<h1>Анализ тональности отзывов на фильмы:\n","строим простые модели</h1>\n"," \n","\n","В этом задании вам предлагается начать разбираться с задачей анализа тональности отзывов на примере сентимент-анализа отзывов на фильмы.\n","\n","Мы будем использовать стандартный датасет из nltk, уже возникавший в одном из примеров в предыдущих курсах. Для того, чтобы импортировать необходимый модуль, напишите:\n","\n"," \n","<code>from nltk.corpus import movie_reviews</code>\n"," \n","\n","Чтобы получить id-шники негативных и позитивных отзывов:\n","\n","<code> \n","negids = movie_reviews.fileids('neg')<br>\n","posids = movie_reviews.fileids('pos')\n","</code> \n","\n","Чтобы получить список негативных отзывов:\n","\n","<code> \n","negfeats = [movie_reviews.words(fileids=[f]) for f in negids]\n","</code> \n","\n","<h2>Инструкция по выполнению</h2>\n","\n","В некоторых пунктах нужно получить ответ - число или строку, которые будет нужно набирать в текстовых файлах и прикреплять в ответах на вопросы. Десятичные дроби записывайте через точку.\n","\n","<ol><li>Создайте список из текстов всех имеющихся отзывов, а также список с классами, которые будет использовать ваш классификатор - 0 для негативных отзывов и 1 для позитивных.</li>\n","<li>Подсчитайте количество отзывов в выборке.</li>\n","<li>Подсчитайте долю класса 1 в выборке.</li>\n","<li>Импортируйте CountVectorizer из sklearn.feature_extraction.text. Попробуйте использовать его с настройками по умолчанию для того, чтобы получить признаковое представление каждого текста. Скорее всего, попытка не увенчается успехом. Разберитесь, в чем причина, и добейтесь того, чтобы метод fit_transform у CountVectorizer успешно отрабатывал. Подсчитайте количество признаков в CountVectorizer. Никакой предварительной обработки текста (удаление стоп-слов, нормализация слов) на этом шаге делать не надо, в качестве признаков должны использоваться частоты слов.</li>\n","<li>Соберите pipeline из CountVectorizer и LogisticRegression c настройками по-умолчанию и с помощью cross_val_score (также со стандартными настройками) оцените получаемое \"из коробки\" качество по accuracy.</li>\n","<li>Аналогично accuracy, оцените качество по ROC AUC.\n","Обучите логистическую регрессию на всей доступной вам выборке и выведите 5 наиболее важных для модели признаков (подумайте, какие именно признаки стоит считать такими). Вам могут пригодиться метод get_feature_names() или поле vocabulary_ у класса CountVectorizer.</li>\n","</ol>"]},{"cell_type":"code","metadata":{"id":"SshozRvtA6I_","executionInfo":{"status":"ok","timestamp":1634196792154,"user_tz":-180,"elapsed":896,"user":{"displayName":"Надежда Чехова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSJHZgegxNfZHz-DHNitm4K7fL7sLHVtvAWS50Ceg=s64","userId":"05232737027527319731"}}},"source":["import numpy as np\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import cross_val_score"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K8bATwTI6JIJ"},"source":["Загружаем датасет"]},{"cell_type":"code","metadata":{"id":"HZlsujh4a9VL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634196792528,"user_tz":-180,"elapsed":379,"user":{"displayName":"Надежда Чехова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSJHZgegxNfZHz-DHNitm4K7fL7sLHVtvAWS50Ceg=s64","userId":"05232737027527319731"}},"outputId":"f61032c5-cb12-46d8-c2f9-339428bf8a04"},"source":["import nltk\n","from nltk.corpus import movie_reviews\n","nltk.download('movie_reviews')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n","[nltk_data]   Package movie_reviews is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"vHFoa7tY6Mst"},"source":["Формируем массив отзывов и их меток (0 - отрицательный отзыв, 1 - положительный)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5AZGbFb7I9-A","executionInfo":{"status":"ok","timestamp":1634196793921,"user_tz":-180,"elapsed":1398,"user":{"displayName":"Надежда Чехова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSJHZgegxNfZHz-DHNitm4K7fL7sLHVtvAWS50Ceg=s64","userId":"05232737027527319731"}},"outputId":"16b0f717-319b-476a-f32c-302506e8dadd"},"source":["negids = movie_reviews.fileids('neg') \n","posids = movie_reviews.fileids('pos')\n","print('Количество положительных отзывов', len(posids))\n","print('Количество отрицательных отзывов', len(negids))\n","\n","neg_reviews = [' '.join(movie_reviews.words(fileids=[f])) for f in negids]\n","pos_reviews = [' '.join(movie_reviews.words(fileids=[f])) for f in posids]\n","corpus = neg_reviews + pos_reviews\n","labels = [0] * len(neg_reviews) + [1] * len(pos_reviews)\n","print('Общее количество отзывов', len(corpus))"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Количество положительных отзывов 1000\n","Количество отрицательных отзывов 1000\n","Общее количество отзывов 2000\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PHSgjPiLAvE_","executionInfo":{"status":"ok","timestamp":1634196795035,"user_tz":-180,"elapsed":1118,"user":{"displayName":"Надежда Чехова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSJHZgegxNfZHz-DHNitm4K7fL7sLHVtvAWS50Ceg=s64","userId":"05232737027527319731"}},"outputId":"162f5245-9669-4704-93a6-db3ed463e2bf"},"source":["vectorizer = CountVectorizer()\n","x = vectorizer.fit_transform(corpus)\n","print('Количество признаков', x.shape[1])"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Количество признаков 39659\n"]}]},{"cell_type":"markdown","metadata":{"id":"Gnex0c45JqtN"},"source":["Оценим качество классификации, рассчитав accuracy и roc-auc"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JJ0uf2KD_7sj","executionInfo":{"status":"ok","timestamp":1634196820663,"user_tz":-180,"elapsed":25634,"user":{"displayName":"Надежда Чехова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSJHZgegxNfZHz-DHNitm4K7fL7sLHVtvAWS50Ceg=s64","userId":"05232737027527319731"}},"outputId":"3a2a4ab9-45c4-4d01-981e-bc7eb9791f24"},"source":["%%time\n","clf = LogisticRegression(max_iter=1000)\n","pline = Pipeline([(\"vectorizer\", vectorizer), (\"classifier\", clf)])\n","print('Точность классификации', cross_val_score(pline, corpus, labels).mean())"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Точность классификации 0.8445\n","CPU times: user 23.6 s, sys: 21.1 s, total: 44.7 s\n","Wall time: 25.5 s\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ex8rxNOXGwfy","executionInfo":{"status":"ok","timestamp":1634196845928,"user_tz":-180,"elapsed":25285,"user":{"displayName":"Надежда Чехова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSJHZgegxNfZHz-DHNitm4K7fL7sLHVtvAWS50Ceg=s64","userId":"05232737027527319731"}},"outputId":"e379da38-247a-4031-a249-f4836fad435e"},"source":["print('roc auc', cross_val_score(pline, corpus, labels, scoring='roc_auc').mean())"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["roc auc 0.9162949999999999\n"]}]},{"cell_type":"markdown","metadata":{"id":"5-oTXxyetcLJ"},"source":["Обучаем модель на всей выборке"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CkQ9xAYLHus1","executionInfo":{"status":"ok","timestamp":1634196852420,"user_tz":-180,"elapsed":6513,"user":{"displayName":"Надежда Чехова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSJHZgegxNfZHz-DHNitm4K7fL7sLHVtvAWS50Ceg=s64","userId":"05232737027527319731"}},"outputId":"9e6c0e4d-05b9-4d5b-a2a4-271b08f83b65"},"source":["pline.fit(corpus, labels)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(memory=None,\n","         steps=[('vectorizer',\n","                 CountVectorizer(analyzer='word', binary=False,\n","                                 decode_error='strict',\n","                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n","                                 input='content', lowercase=True, max_df=1.0,\n","                                 max_features=None, min_df=1,\n","                                 ngram_range=(1, 1), preprocessor=None,\n","                                 stop_words=None, strip_accents=None,\n","                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n","                                 tokenizer=None, vocabulary=None)),\n","                ('classifier',\n","                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n","                                    fit_intercept=True, intercept_scaling=1,\n","                                    l1_ratio=None, max_iter=1000,\n","                                    multi_class='auto', n_jobs=None,\n","                                    penalty='l2', random_state=None,\n","                                    solver='lbfgs', tol=0.0001, verbose=0,\n","                                    warm_start=False))],\n","         verbose=False)"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"WZgJ_lGftu4p"},"source":["Выводим 5 наиболее значимых слов, им соответствуют максимальные по модулю веса модели"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"6zavL8WFIxt0","executionInfo":{"status":"ok","timestamp":1634196852421,"user_tz":-180,"elapsed":31,"user":{"displayName":"Надежда Чехова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSJHZgegxNfZHz-DHNitm4K7fL7sLHVtvAWS50Ceg=s64","userId":"05232737027527319731"}},"outputId":"f147b026-b21c-42d0-afee-3654f733a4b1"},"source":["imp_indexes = np.argsort(np.abs(clf.coef_[0]))[-5:][::-1]\n","res = [vectorizer.get_feature_names()[i] for i in imp_indexes]\n","''.join(res)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'badunfortunatelyworstfunnothing'"]},"metadata":{},"execution_count":8}]}]}